{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "contrary-chance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 32)\n",
      "['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9', 'cat10', 'cat11', 'cat12', 'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18', 'cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10'] ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9', 'cat10', 'cat11', 'cat12', 'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18'] ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10'] 30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"./train.csv\")\n",
    "df_test = pd.read_csv(\"./test.csv\")\n",
    "df_test.loc[:, \"target\"] = -1\n",
    "df_whole = pd.concat([df_train, df_test], ignore_index=True)\n",
    "print(df_train.shape)\n",
    "features = [f for f in df_train.columns if f not in [\"id\", \"target\"]]\n",
    "cat_features = [f for f in features if f.startswith(\"cat\") == True]\n",
    "cont_features = [f for f in features if f.startswith(\"cat\") == False]\n",
    "print(features, cat_features, cont_features, len(features))\n",
    "\n",
    "test_ids = df_test.loc[:,\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "checked-bicycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         A\n",
      "1         A\n",
      "2         A\n",
      "3         A\n",
      "4         G\n",
      "         ..\n",
      "499995    A\n",
      "499996    A\n",
      "499997    D\n",
      "499998    A\n",
      "499999    A\n",
      "Name: cat2, Length: 500000, dtype: category\n",
      "Categories (19, object): ['A', 'B', 'C', 'D', ..., 'Q', 'R', 'S', 'U']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for submission\n",
    "df_whole.loc[:, cat_features] = df_whole.loc[:, cat_features].astype('category')      \n",
    "print(df_whole[features[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "infinite-chase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 32) (200000, 32)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_whole.loc[df_whole.loc[:, \"target\"] != -1, :]\n",
    "df_test = df_whole.loc[df_whole.loc[:, \"target\"] == -1, :]\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "choice-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def auc_train_test(model, x_train, x_test, y_train, y_test, early_stopping_rounds=None):\n",
    "    if early_stopping_rounds == None: \n",
    "        model.fit(x_train, y_train)\n",
    "    else:\n",
    "        model.fit(x_train, y_train,\n",
    "              eval_set=(x_test, y_test),\n",
    "              early_stopping_rounds=early_stopping_rounds,\n",
    "              verbose=200)\n",
    "    preds = model.predict_proba(x_test)[:, 1]\n",
    "    return metrics.roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "atlantic-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Functions for KFold evaluation and prediction\n",
    "def create(hyperparams):\n",
    "    \"\"\"Create LGBM Classifier for a given set of hyper-parameters.\"\"\"\n",
    "    model = LGBMClassifier(**hyperparams)\n",
    "    return model\n",
    "\n",
    "def fit(model, X, y):\n",
    "    \"\"\"Simple training of a given model.\"\"\"\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def fit_with_stop(model, X, y, X_val, y_val, esr):\n",
    "    \"\"\"Advanced training with early stopping.\"\"\"\n",
    "    model.fit(X, y,\n",
    "              eval_set=(X_val, y_val),\n",
    "              early_stopping_rounds=esr,\n",
    "              verbose=200)\n",
    "    return model\n",
    "\n",
    "def evaluate(model, X, y):\n",
    "    \"\"\"Compute AUC for a given model.\"\"\"\n",
    "    yp = model.predict_proba(X)[:, 1]\n",
    "    auc_score = roc_auc_score(y, yp)\n",
    "    return auc_score\n",
    "\n",
    "def single_evaluation(X, y, hyperparams, esr=100):\n",
    "    \"\"\" Simple split\"\"\"\n",
    "    scores = []\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X , y, test_size = 0.028059109276941666 , random_state = 42)\n",
    "\n",
    "    model = create(hyperparams)\n",
    "    model = fit_with_stop(model, X_train, y_train, X_val, y_val, esr)\n",
    "    train_score = evaluate(model, X_train, y_train)\n",
    "    val_score = evaluate(model, X_val, y_val)\n",
    "    print(f\"Eval AUC: {val_score}\")\n",
    "    scores.append((train_score, val_score))\n",
    "    scores = pd.DataFrame(scores, columns=['train score', 'validation score'])\n",
    "    return scores\n",
    "\n",
    "def kfold_evaluation(X, y, k, hyperparams, esr=100):\n",
    "    \"\"\"Run a KFlod evaluation.\"\"\"\n",
    "    scores = []\n",
    "    \n",
    "    print(f\"\\n------ {k}-fold evaluation -----\")\n",
    "    print(hyperparams)\n",
    "    \n",
    "    kf = KFold(k)\n",
    "    for i, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\n----- FOLD {i} -----\")\n",
    "        \n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_val = X.iloc[test_idx]\n",
    "        y_val = y.iloc[test_idx]\n",
    "        \n",
    "        model = create(hyperparams)\n",
    "        model = fit_with_stop(model, X_train, y_train, X_val, y_val, esr)\n",
    "        train_score = evaluate(model, X_train, y_train)\n",
    "        val_score = evaluate(model, X_val, y_val)\n",
    "        scores.append((train_score, val_score))\n",
    "        \n",
    "        print(f\"Fold {i} | Eval AUC: {val_score}\")\n",
    "        \n",
    "        \n",
    "    scores = pd.DataFrame(scores, columns=['train score', 'validation score'])\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def kfold_prediction(X, y, X_test, k, hyperparams, esr=100):\n",
    "    \"\"\"Make predictions with a bagged model based on KFold.\"\"\"\n",
    "    yp = np.zeros(len(X_test))\n",
    "    \n",
    "    print(f\"\\n------ {k}-fold evaluation -----\")\n",
    "    print(hyperparams)\n",
    "    \n",
    "    kf = KFold(k)\n",
    "    for i, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\n----- FOLD {i} -----\")\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_val = X.iloc[test_idx]\n",
    "        y_val = y.iloc[test_idx]\n",
    "        \n",
    "        model = create(hyperparams)\n",
    "        model = fit_with_stop(model, X_train, y_train, X_val, y_val, esr)\n",
    "        yp += model.predict_proba(X_test)[:, 1] / k\n",
    "    \n",
    "    return yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "limited-hardwood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 30) (200000, 30)\n",
      "(300000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#  for training\n",
    "# x_train, x_test, y_train, y_test = train_test_split(df_train.loc[:, features], df_train.loc[:, \"target\"], random_state=10, stratify=df_train.loc[:, \"target\"])\n",
    "\n",
    "# for submission\n",
    "x_train, x_test, y_train = df_train.loc[:, features], df_test.loc[:, features], df_train.loc[:, \"target\"]\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape)\n",
    "# print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "headed-crime",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 19) (200000, 19)\n",
      "(300000, 49) (200000, 49)\n"
     ]
    }
   ],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "\n",
    "def encode(enc, x_train, y_train, x_test):\n",
    "    x_train_transformed = enc.fit_transform(x_train, y_train)\n",
    "    x_test_transformed = enc.transform(x_test)\n",
    "    return x_train_transformed, x_test_transformed\n",
    "\n",
    "te = TargetEncoder(cols=cat_features)\n",
    "x1, x2 = encode(te, x_train.loc[:, cat_features], y_train, x_test.loc[:, cat_features])\n",
    "print(x1.shape, x2.shape)\n",
    "\n",
    "x_train = x_train.join(x1, lsuffix=\"\", rsuffix=\"_enc\")\n",
    "x_test = x_test.join(x2, lsuffix=\"\", rsuffix=\"_enc\")\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "purple-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('category')\n",
    "# y_test = y_test.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "strong-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=[0, 1], ordered=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "reserved-trading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ 10-fold evaluation -----\n",
      "{'n_estimators': 10000, 'learning_rate': 0.05, 'metric': 'auc', 'num_leaves': 237, 'max_depth': 31, 'reg_alpha': 4.571551679011291, 'reg_lambda': 12.577178152686312, 'colsample_bytree': 0.2301028578381579, 'subsample': 0.9390970911797094, 'cat_smooth': 47.58241398941176}\n",
      "\n",
      "----- FOLD 0 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\tvalid_0's auc: 0.896294\n",
      "[400]\tvalid_0's auc: 0.896997\n",
      "[600]\tvalid_0's auc: 0.896781\n",
      "[800]\tvalid_0's auc: 0.896385\n",
      "Early stopping, best iteration is:\n",
      "[392]\tvalid_0's auc: 0.897034\n",
      "\n",
      "----- FOLD 1 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\tvalid_0's auc: 0.896731\n",
      "[400]\tvalid_0's auc: 0.897918\n",
      "[600]\tvalid_0's auc: 0.897807\n",
      "[800]\tvalid_0's auc: 0.897403\n",
      "Early stopping, best iteration is:\n",
      "[468]\tvalid_0's auc: 0.897999\n",
      "\n",
      "----- FOLD 2 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\tvalid_0's auc: 0.896685\n",
      "[400]\tvalid_0's auc: 0.897874\n",
      "[600]\tvalid_0's auc: 0.897932\n",
      "[800]\tvalid_0's auc: 0.89746\n",
      "[1000]\tvalid_0's auc: 0.896913\n",
      "Early stopping, best iteration is:\n",
      "[542]\tvalid_0's auc: 0.898078\n",
      "\n",
      "----- FOLD 3 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\tvalid_0's auc: 0.895142\n",
      "[400]\tvalid_0's auc: 0.897054\n",
      "[600]\tvalid_0's auc: 0.8975\n",
      "[800]\tvalid_0's auc: 0.897579\n",
      "[1000]\tvalid_0's auc: 0.897427\n",
      "[1200]\tvalid_0's auc: 0.897125\n",
      "Early stopping, best iteration is:\n",
      "[878]\tvalid_0's auc: 0.897628\n",
      "\n",
      "----- FOLD 4 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\tvalid_0's auc: 0.8978\n",
      "[400]\tvalid_0's auc: 0.899139\n",
      "[600]\tvalid_0's auc: 0.899125\n",
      "[800]\tvalid_0's auc: 0.898646\n",
      "Early stopping, best iteration is:\n",
      "[462]\tvalid_0's auc: 0.899286\n",
      "\n",
      "----- FOLD 5 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\tvalid_0's auc: 0.895412\n",
      "[400]\tvalid_0's auc: 0.896735\n",
      "[600]\tvalid_0's auc: 0.896682\n",
      "[800]\tvalid_0's auc: 0.896384\n",
      "Early stopping, best iteration is:\n",
      "[489]\tvalid_0's auc: 0.896749\n",
      "\n",
      "----- FOLD 6 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\tvalid_0's auc: 0.893099\n",
      "[400]\tvalid_0's auc: 0.894654\n",
      "[600]\tvalid_0's auc: 0.894668\n",
      "[800]\tvalid_0's auc: 0.894456\n",
      "Early stopping, best iteration is:\n",
      "[439]\tvalid_0's auc: 0.89476\n",
      "\n",
      "----- FOLD 7 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\tvalid_0's auc: 0.894966\n",
      "[400]\tvalid_0's auc: 0.896051\n",
      "[600]\tvalid_0's auc: 0.895623\n",
      "[800]\tvalid_0's auc: 0.895191\n",
      "Early stopping, best iteration is:\n",
      "[317]\tvalid_0's auc: 0.896071\n",
      "\n",
      "----- FOLD 8 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\tvalid_0's auc: 0.897141\n",
      "[400]\tvalid_0's auc: 0.898075\n",
      "[600]\tvalid_0's auc: 0.897992\n",
      "[800]\tvalid_0's auc: 0.897573\n",
      "Early stopping, best iteration is:\n",
      "[413]\tvalid_0's auc: 0.898137\n",
      "\n",
      "----- FOLD 9 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/root/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\tvalid_0's auc: 0.89326\n",
      "[400]\tvalid_0's auc: 0.894502\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fdf95711cfc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# clf = LGBMClassifier(**BEST_PARAMS,n_jobs= -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# clf.fit(x_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mkfold_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBEST_PARAMS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-4a73d89df597>\u001b[0m in \u001b[0;36mkfold_prediction\u001b[0;34m(X, y, X_test, k, hyperparams, esr)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_with_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mesr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0myp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-4a73d89df597>\u001b[0m in \u001b[0;36mfit_with_stop\u001b[0;34m(model, X, y, X_val, y_val, esr)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_with_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mesr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m\"\"\"Advanced training with early stopping.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     model.fit(X, y,\n\u001b[0m\u001b[1;32m     21\u001b[0m               \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mesr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         super(LGBMClassifier, self).fit(X, _y, sample_weight=sample_weight,\n\u001b[0m\u001b[1;32m    848\u001b[0m                                         \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m                                         \u001b[0meval_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0minit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         self._Booster = train(params, train_set,\n\u001b[0m\u001b[1;32m    613\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TPS-MAR/lib/python3.9/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2457\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2458\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2459\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2460\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for submission\n",
    "K =10\n",
    "BEST_PARAMS = {'n_estimators': 10000,\n",
    " 'learning_rate': 0.05,\n",
    " 'metric': 'auc',\n",
    " 'num_leaves': 237,\n",
    " 'max_depth': 31,\n",
    " 'reg_alpha': 4.571551679011291,\n",
    " 'reg_lambda': 12.577178152686312,\n",
    " 'colsample_bytree': 0.2301028578381579,\n",
    " 'subsample': 0.9390970911797094,\n",
    " 'cat_smooth': 47.58241398941176\n",
    "              }\n",
    "# from lightgbm import LGBMClassifier\n",
    "# clf = LGBMClassifier(**BEST_PARAMS,n_jobs= -1)\n",
    "# clf.fit(x_train, y_train)\n",
    "kfold_prediction(x_train, y_train, x_test, K, BEST_PARAMS, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "offshore-lecture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.023433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.120639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.198303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.040009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>499983</td>\n",
       "      <td>0.981807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>499984</td>\n",
       "      <td>0.011967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>499987</td>\n",
       "      <td>0.610144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>499994</td>\n",
       "      <td>0.221175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>499998</td>\n",
       "      <td>0.507888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    target\n",
       "0            5  0.023433\n",
       "1            6  0.120639\n",
       "2            8  0.000996\n",
       "3            9  0.198303\n",
       "4           11  0.040009\n",
       "...        ...       ...\n",
       "199995  499983  0.981807\n",
       "199996  499984  0.011967\n",
       "199997  499987  0.610144\n",
       "199998  499994  0.221175\n",
       "199999  499998  0.507888\n",
       "\n",
       "[200000 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_test.loc[:, \"target\"] = clf.predict_proba(x_test)[:,1]\n",
    "# x_test = x_test.reset_index()\n",
    "# x_test[\"id\"] = test_ids\n",
    "x_test.loc[:, [\"id\", \"target\"]].to_csv(\"./output.csv\", index=False)\n",
    "x_test.loc[:, [\"id\", \"target\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
